'use client'

import { useState, useEffect, useRef } from 'react'
import { useRouter } from 'next/navigation'
import { ArrowLeft, Mic, Music, Download, Loader2, Upload, Play, Pause, Volume2, VolumeX } from 'lucide-react'
import { auth, storage, db } from '@/lib/firebase'
import { ref, listAll, getDownloadURL, uploadBytes } from 'firebase/storage'
import { collection, addDoc, serverTimestamp } from 'firebase/firestore'
import { onAuthStateChanged } from 'firebase/auth'
import BottomNav from '@/components/BottomNav'

export default function AnnouncementPage() {
  const router = useRouter()
  const [user, setUser] = useState<any>(null)
  const [text, setText] = useState('ì ì‹œ í›„ ì˜ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì°¾ì•„ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.')
  const [selectedBgm, setSelectedBgm] = useState<string>('none')
  const [bgmFiles, setBgmFiles] = useState<Array<{ name: string; url: string; type: 'public' | 'private' }>>([])
  const [loadingBgm, setLoadingBgm] = useState(false)
  const [isGenerating, setIsGenerating] = useState(false)
  const [audioUrl, setAudioUrl] = useState<string | null>(null)
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null)
  const [isPlaying, setIsPlaying] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const [uploadingBgm, setUploadingBgm] = useState(false)
  const audioRef = useRef<HTMLAudioElement>(null)
  const [volume, setVolume] = useState(1)
  
  // TTS ìŒì„± ì„¤ì •
  const [voiceLang, setVoiceLang] = useState<string>('ko') // ì–¸ì–´
  const [voiceSpeed, setVoiceSpeed] = useState<'normal' | 'slow'>('normal') // ì†ë„
  const [voiceGender, setVoiceGender] = useState<'male' | 'female' | 'neutral'>('neutral') // ìŒì„± ì„±ë³„
  const [voiceTld, setVoiceTld] = useState<string>('com') // TLD (ë°©ì–¸)

  // ì‚¬ìš©ì ì¸ì¦ í™•ì¸
  useEffect(() => {
    if (!auth) return
    const unsubscribe = onAuthStateChanged(auth, (currentUser) => {
      setUser(currentUser)
    })
    return () => unsubscribe()
  }, [])

  // BGM íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
  useEffect(() => {
    loadBgmFiles()
  }, [user])

  const loadBgmFiles = async () => {
    if (!storage) return

    setLoadingBgm(true)
    setError(null)
    
    try {
      const allFiles: Array<{ name: string; url: string; type: 'public' | 'private' }> = []

      // 1. ê³µìš© BGM ë¡œë“œ (ëª¨ë“  ì‚¬ìš©ìê°€ ì‚¬ìš© ê°€ëŠ¥)
      try {
        const publicBgmRef = ref(storage, 'bgm/public')
        const publicFileList = await listAll(publicBgmRef)
        
        const publicFiles = await Promise.all(
          publicFileList.items.map(async (item) => {
            const url = await getDownloadURL(item)
            return { 
              name: item.name, 
              url,
              type: 'public' as const
            }
          })
        )
        
        allFiles.push(...publicFiles)
      } catch (error: any) {
        // ê³µìš© í´ë”ê°€ ì—†ê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ëŠ” ë¬´ì‹œ
        if (error.code !== 'storage/object-not-found' && error.code !== 'storage/unauthorized') {
          console.warn('ê³µìš© BGM íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', error)
        }
      }

      // 2. ê°œì¸ BGM ë¡œë“œ (ë¡œê·¸ì¸í•œ ì‚¬ìš©ìë§Œ)
      if (user) {
        try {
          const privateBgmRef = ref(storage, `bgm/${user.uid}`)
          const privateFileList = await listAll(privateBgmRef)
          
          const privateFiles = await Promise.all(
            privateFileList.items.map(async (item) => {
              const url = await getDownloadURL(item)
              return { 
                name: item.name, 
                url,
                type: 'private' as const
              }
            })
          )
          
          allFiles.push(...privateFiles)
        } catch (error: any) {
          // ê°œì¸ í´ë”ê°€ ì—†ê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ëŠ” ë¬´ì‹œ
          if (error.code !== 'storage/object-not-found' && error.code !== 'storage/unauthorized') {
            console.warn('ê°œì¸ BGM íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:', error)
          }
        }
      }
      
      setBgmFiles(allFiles)
    } catch (error: any) {
      console.error('BGM íŒŒì¼ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜:', error)
      setBgmFiles([])
    } finally {
      setLoadingBgm(false)
    }
  }

  // BGM íŒŒì¼ ì—…ë¡œë“œ
  const handleBgmUpload = async (file: File) => {
    if (!user || !storage) {
      alert('ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.')
      return
    }

    if (!file.type.startsWith('audio/')) {
      alert('ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.')
      return
    }

    if (file.size > 10 * 1024 * 1024) {
      alert('íŒŒì¼ í¬ê¸°ëŠ” 10MB ì´í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.')
      return
    }

    setUploadingBgm(true)
    setError(null)

    try {
      const bgmRef = ref(storage, `bgm/${user.uid}/${Date.now()}_${file.name}`)
      await uploadBytes(bgmRef, file)
      await loadBgmFiles()
      alert('BGM íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.')
    } catch (error: any) {
      console.error('BGM ì—…ë¡œë“œ ì‹¤íŒ¨:', error)
      alert('BGM ì—…ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + (error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
    } finally {
      setUploadingBgm(false)
    }
  }

  /**
   * í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ TTS ìƒì„± (Web Speech API ì‚¬ìš© - ì„œë²„ ë¶ˆí•„ìš”)
   * ë¸Œë¼ìš°ì € ë‚´ì¥ Speech Synthesis APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë²„ ì—†ì´ TTS ìƒì„±
   * 
   * ëª¨ë°”ì¼ì—ì„œ í™•ì‹¤í•˜ê²Œ ì‘ë™í•˜ë„ë¡ Audio ìš”ì†Œì™€ MediaRecorderë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì¬ìƒì„ ìº¡ì²˜
   */
  const generateSpeechWithWebAPI = async (
    text: string,
    lang: string,
    speed: 'normal' | 'slow',
    gender: 'male' | 'female' | 'neutral'
  ): Promise<Blob> => {
    return new Promise((resolve, reject) => {
      let audioContext: AudioContext | null = null
      let mediaRecorder: MediaRecorder | null = null
      
      const cleanup = () => {
        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
          try { mediaRecorder.stop() } catch {}
        }
        if (audioContext && audioContext.state !== 'closed') {
          audioContext.close().catch(() => {})
        }
        speechSynthesis.cancel()
      }

      try {
        // Speech Synthesis API ì§€ì› í™•ì¸
        if (!('speechSynthesis' in window) || !('SpeechSynthesisUtterance' in window)) {
          reject(new Error('ë¸Œë¼ìš°ì €ê°€ ìŒì„± í•©ì„±ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ë˜ëŠ” Safarië¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.'))
          return
        }

        console.log('Web Speech APIë¡œ TTS ìƒì„± ì‹œì‘:', { text: text.substring(0, 50), lang, speed })

        // AudioContext ìƒì„±
        try {
          const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
          if (!AudioContextClass) {
            throw new Error('AudioContextë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
          }
          audioContext = new AudioContextClass()
          
          if (audioContext.state === 'suspended') {
            audioContext.resume().catch(() => {})
          }
        } catch (ctxError: any) {
          reject(new Error('ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ' + (ctxError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
          return
        }

        if (!audioContext) {
          reject(new Error('AudioContext ìƒì„± ì‹¤íŒ¨'))
          return
        }

        // Speech Synthesis Utterance ìƒì„±
        const utterance = new SpeechSynthesisUtterance(text)
        
        // ì–¸ì–´ ì„¤ì •
        const langMap: Record<string, string> = {
          'ko': 'ko-KR',
          'en': 'en-US',
          'ja': 'ja-JP',
          'zh': 'zh-CN',
          'es': 'es-ES',
          'fr': 'fr-FR',
          'de': 'de-DE'
        }
        utterance.lang = langMap[lang] || lang
        
        // ì†ë„ ë° í”¼ì¹˜ ì„¤ì •
        utterance.rate = speed === 'slow' ? 0.8 : 1.0
        utterance.pitch = 1.0
        utterance.volume = 1.0
        
        // ìŒì„± ì„ íƒ
        const loadVoices = (): SpeechSynthesisVoice[] => {
          return speechSynthesis.getVoices()
        }
        
        // ìŒì„± ëª©ë¡ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        let voices = loadVoices()
        if (voices.length === 0) {
          // ìŒì„±ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì´ë²¤íŠ¸ ëŒ€ê¸°
          speechSynthesis.onvoiceschanged = () => {
            voices = loadVoices()
            selectVoice(voices)
          }
          // íƒ€ì„ì•„ì›ƒ ì„¤ì • (3ì´ˆ)
          setTimeout(() => {
            voices = loadVoices()
            if (voices.length === 0) {
              reject(new Error('ìŒì„± ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'))
              cleanup()
              return
            }
            selectVoice(voices)
          }, 3000)
        } else {
          selectVoice(voices)
        }

        const selectVoice = (voices: SpeechSynthesisVoice[]) => {
          let selectedVoice: SpeechSynthesisVoice | null = null

          if (lang === 'ko') {
            const koVoices = voices.filter(v => v.lang.startsWith('ko'))
            if (koVoices.length > 0) {
              if (gender === 'female') {
                selectedVoice = koVoices.find(v => 
                  v.name.includes('ì—¬') || 
                  v.name.toLowerCase().includes('female') ||
                  v.name.includes('Yuna') ||
                  v.name.includes('Sora')
                ) || koVoices[0]
              } else if (gender === 'male') {
                selectedVoice = koVoices.find(v => 
                  v.name.includes('ë‚¨') || 
                  v.name.toLowerCase().includes('male')
                ) || koVoices[0]
              } else {
                selectedVoice = koVoices[0]
              }
            }
          } else {
            const langVoices = voices.filter(v => v.lang.startsWith(lang))
            if (langVoices.length > 0) {
              selectedVoice = langVoices[0]
            } else {
              // ì–¸ì–´ ì½”ë“œì˜ ì²« ë¶€ë¶„ë§Œ ë§¤ì¹­
              const langPrefix = lang.split('-')[0]
              selectedVoice = voices.find(v => v.lang.startsWith(langPrefix)) || voices[0]
            }
          }

          if (selectedVoice) {
            utterance.voice = selectedVoice
            console.log('ì„ íƒëœ ìŒì„±:', selectedVoice.name, selectedVoice.lang)
          }

          startRecording()
        }

        const startRecording = () => {
          try {
            // MediaStreamDestination ìƒì„±
            const destination = audioContext!.createMediaStreamDestination()
            
            // MediaRecorder ì„¤ì •
            const mimeTypes = [
              'audio/webm;codecs=opus',
              'audio/webm',
              'audio/ogg;codecs=opus',
              'audio/mp4'
            ]
            const selectedMimeType = mimeTypes.find(mime => MediaRecorder.isTypeSupported(mime)) || 'audio/webm'
            
            console.log('MediaRecorder MIME íƒ€ì…:', selectedMimeType)
            
            mediaRecorder = new MediaRecorder(destination.stream, {
              mimeType: selectedMimeType
            })

            const chunks: Blob[] = []

            mediaRecorder.ondataavailable = (event) => {
              if (event.data && event.data.size > 0) {
                chunks.push(event.data)
              }
            }

            mediaRecorder.onstop = () => {
              const blob = new Blob(chunks, { type: selectedMimeType })
              console.log('TTS ë…¹ìŒ ì™„ë£Œ:', { size: blob.size, type: blob.type })
              
              if (blob.size === 0) {
                reject(new Error('ë…¹ìŒëœ ì˜¤ë””ì˜¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'))
                cleanup()
                return
              }
              
              resolve(blob)
              cleanup()
            }

            mediaRecorder.onerror = (event: any) => {
              console.error('MediaRecorder ì˜¤ë¥˜:', event)
              reject(new Error('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + (event.error?.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
              cleanup()
            }

            // SpeechSynthesis ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
            utterance.onstart = () => {
              console.log('TTS ì¬ìƒ ì‹œì‘')
              try {
                mediaRecorder!.start(100) // 100msë§ˆë‹¤ ë°ì´í„° ìˆ˜ì‹ 
              } catch (e: any) {
                console.error('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', e)
                reject(new Error('ë…¹ìŒ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + (e.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
                cleanup()
              }
            }

            utterance.onend = () => {
              console.log('TTS ì¬ìƒ ì™„ë£Œ')
              setTimeout(() => {
                if (mediaRecorder && mediaRecorder.state === 'recording') {
                  mediaRecorder.stop()
                }
              }, 500) // ì•½ê°„ì˜ ì—¬ìœ  ì‹œê°„
            }

            utterance.onerror = (event: any) => {
              console.error('Speech Synthesis ì˜¤ë¥˜:', event)
              if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop()
              }
              reject(new Error('ìŒì„± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ' + (event.error || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
              cleanup()
            }

            // ìŒì„± í•©ì„± ì‹œì‘
            speechSynthesis.cancel()
            
            // AudioContextê°€ suspended ìƒíƒœì´ë©´ resume
            if (audioContext!.state === 'suspended') {
              audioContext!.resume().then(() => {
                speechSynthesis.speak(utterance)
              }).catch((e) => {
                console.error('AudioContext resume ì‹¤íŒ¨:', e)
                speechSynthesis.speak(utterance) // resume ì‹¤íŒ¨í•´ë„ ì§„í–‰
              })
            } else {
              speechSynthesis.speak(utterance)
            }

            // íƒ€ì„ì•„ì›ƒ ì•ˆì „ì¥ì¹˜ (30ì´ˆ)
            setTimeout(() => {
              if (mediaRecorder && mediaRecorder.state === 'recording') {
                console.warn('íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ë…¹ìŒ ì¤‘ì§€')
                mediaRecorder.stop()
              }
            }, 30000)

          } catch (error: any) {
            console.error('ë…¹ìŒ ì„¤ì • ì˜¤ë¥˜:', error)
            reject(new Error('ë…¹ìŒ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + (error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
            cleanup()
          }
        }

      } catch (error: any) {
        console.error('TTS ìƒì„± ì˜¤ë¥˜:', error)
        reject(new Error('ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: ' + (error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')))
        cleanup()
      }
    })
  }

  /**
   * ì˜¤ë””ì˜¤ ë¯¹ì‹± í•¨ìˆ˜ (AudioBuffer ì§ì ‘ ì¡°ì‘ - ëª¨ë°”ì¼ ìµœì í™”)
   * 
   * ëª¨ë°”ì¼ì—ì„œ ê°€ì¥ í™•ì‹¤í•˜ê²Œ ì‘ë™í•˜ëŠ” ë°©ë²•: AudioBufferë¥¼ ì§ì ‘ ì¡°ì‘í•˜ì—¬ ë¯¹ì‹±
   * MediaRecorderë‚˜ Audio ìš”ì†Œ ì¬ìƒ ì—†ì´ ì§ì ‘ ë°ì´í„°ë¥¼ ì¡°ì‘í•˜ë¯€ë¡œ ê°€ì¥ ì•ˆì •ì 
   * 
   * [ë¯¹ì‹± ëª…ì„¸]
   * 1. Voice ë³¼ë¥¨: 1.0 (100%) - ë©”ì¸ ì˜¤ë””ì˜¤
   * 2. BGM ë³¼ë¥¨: 0.2 (20%) - ëª©ì†Œë¦¬ì— ë¬»íˆì§€ ì•Šê²Œ ì€ì€í•˜ê²Œ
   * 3. ê¸¸ì´ ë§ì¶¤: ëª©ì†Œë¦¬ê°€ ëë‚˜ë©´ BGMë„ í˜ì´ë“œì•„ì›ƒ(Fade out) ë˜ë©° 2ì´ˆ ë’¤ ëë‚˜ê²Œ ì²˜ë¦¬
   * 
   * @param voiceBlob - TTSë¡œ ìƒì„±ëœ ëª©ì†Œë¦¬ ì˜¤ë””ì˜¤ Blob
   * @param bgmUrl - ë°°ê²½ìŒì•… íŒŒì¼ URL
   * @returns ë¯¹ì‹±ëœ ìµœì¢… ì˜¤ë””ì˜¤ Blob
   */
  const mixAudio = async (voiceBlob: Blob, bgmUrl: string): Promise<Blob> => {
    let audioContext: AudioContext | null = null
    let offlineContext: OfflineAudioContext | null = null
    
    try {
      console.log('ğŸµ AudioBuffer ì§ì ‘ ë¯¹ì‹± ì‹œì‘ (ëª¨ë°”ì¼ ìµœì í™”)')
      
      // Step 1: AudioContext ìƒì„± (ë””ì½”ë”© ë° ì²˜ë¦¬ìš©)
      // ëª¨ë°”ì¼ì—ì„œ ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í›„ ìƒì„±í•´ì•¼ í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
      try {
        const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
        if (!AudioContextClass) {
          throw new Error('ë¸Œë¼ìš°ì €ê°€ AudioContextë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
        }
        audioContext = new AudioContextClass()
        
        // AudioContextê°€ suspended ìƒíƒœì´ë©´ resume
        if (audioContext.state === 'suspended') {
          await audioContext.resume()
          console.log('AudioContext resumed:', audioContext.state)
        }
      } catch (ctxError: any) {
        throw new Error('ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ì˜¤ë¥˜: ' + (ctxError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
      }
      
      if (!audioContext) {
        throw new Error('AudioContext ìƒì„± ì‹¤íŒ¨')
      }
      
      // Step 2: Voice ì˜¤ë””ì˜¤ ë””ì½”ë”©
      console.log('Voice ì˜¤ë””ì˜¤ ë””ì½”ë”© ì¤‘...')
      let voiceBuffer: AudioBuffer
      try {
        const voiceArrayBuffer = await voiceBlob.arrayBuffer()
        voiceBuffer = await audioContext.decodeAudioData(voiceArrayBuffer.slice(0))
      } catch (decodeError: any) {
        throw new Error('Voice ì˜¤ë””ì˜¤ë¥¼ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: ' + (decodeError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
      }
      const voiceDuration = voiceBuffer.duration
      const sampleRate = voiceBuffer.sampleRate
      const numChannels = voiceBuffer.numberOfChannels
      
      console.log('Voice ë””ì½”ë”© ì™„ë£Œ:', {
        duration: voiceDuration.toFixed(2),
        sampleRate,
        channels: numChannels
      })
      
      // Step 3: BGM ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë””ì½”ë”©
      console.log('BGM ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ë””ì½”ë”© ì¤‘...')
      let bgmBuffer: AudioBuffer
      try {
        const bgmResponse = await fetch(bgmUrl)
        if (!bgmResponse.ok) {
          throw new Error(`BGM íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (HTTP ${bgmResponse.status})`)
        }
        const bgmArrayBuffer = await bgmResponse.arrayBuffer()
        bgmBuffer = await audioContext.decodeAudioData(bgmArrayBuffer.slice(0))
      } catch (bgmError: any) {
        throw new Error('BGM ì˜¤ë””ì˜¤ë¥¼ ë¶ˆëŸ¬ì˜¤ê±°ë‚˜ ë””ì½”ë”©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì˜¤ë¥˜: ' + (bgmError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
      }
      
      console.log('BGM ë””ì½”ë”© ì™„ë£Œ:', {
        duration: bgmBuffer.duration.toFixed(2),
        sampleRate: bgmBuffer.sampleRate
      })
      
      // Step 4: ìµœì¢… ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° (Voice + 2ì´ˆ í˜ì´ë“œì•„ì›ƒ)
      const targetDuration = voiceDuration + 2
      const totalSamples = Math.ceil(targetDuration * sampleRate)
      
      console.log('ë¯¹ì‹± íŒŒë¼ë¯¸í„°:', {
        voiceDuration: voiceDuration.toFixed(2),
        targetDuration: targetDuration.toFixed(2),
        totalSamples
      })
      
      // Step 5: OfflineAudioContextë¡œ ì˜¤í”„ë¼ì¸ ë¯¹ì‹±
      try {
        offlineContext = new OfflineAudioContext(
          sampleRate,
          totalSamples,
          numChannels // Voice ì±„ë„ ìˆ˜ ì‚¬ìš©
        )
      } catch (offlineError: any) {
        throw new Error('ì˜¤í”„ë¼ì¸ ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì €ê°€ ì´ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜: ' + (offlineError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'))
      }
      
      if (!offlineContext) {
        throw new Error('OfflineAudioContext ìƒì„± ì‹¤íŒ¨')
      }
      
      // Voice ì†ŒìŠ¤ ìƒì„± (100% ë³¼ë¥¨)
      const voiceSource = offlineContext.createBufferSource()
      voiceSource.buffer = voiceBuffer
      const voiceGain = offlineContext.createGain()
      voiceGain.gain.value = 1.0
      voiceSource.connect(voiceGain)
      voiceGain.connect(offlineContext.destination)
      
      // BGM ì†ŒìŠ¤ ìƒì„± (20% ë³¼ë¥¨, ë°˜ë³µ ì¬ìƒ)
      const bgmSource = offlineContext.createBufferSource()
      bgmSource.buffer = bgmBuffer
      bgmSource.loop = true
      const bgmGain = offlineContext.createGain()
      bgmGain.gain.value = 0.2 // 20% ë³¼ë¥¨
      
      // BGM í˜ì´ë“œì•„ì›ƒ ì„¤ì • (Voice ëë‚˜ë©´ 2ì´ˆê°„ í˜ì´ë“œì•„ì›ƒ)
      const fadeOutStart = voiceDuration
      const fadeOutEnd = targetDuration
      bgmGain.gain.setValueAtTime(0.2, fadeOutStart)
      bgmGain.gain.linearRampToValueAtTime(0, fadeOutEnd)
      
      bgmSource.connect(bgmGain)
      bgmGain.connect(offlineContext.destination)
      
      // Step 6: ì˜¤í”„ë¼ì¸ ë Œë”ë§ (ì‹¤ì œ ì¬ìƒ ì—†ì´ ì²˜ë¦¬)
      console.log('ì˜¤í”„ë¼ì¸ ë Œë”ë§ ì‹œì‘...')
      voiceSource.start(0)
      bgmSource.start(0)
      
      const renderedBuffer = await offlineContext.startRendering()
      
      console.log('ì˜¤í”„ë¼ì¸ ë Œë”ë§ ì™„ë£Œ:', {
        duration: renderedBuffer.duration.toFixed(2),
        sampleRate: renderedBuffer.sampleRate,
        channels: renderedBuffer.numberOfChannels,
        samples: renderedBuffer.length
      })
      
      // Step 7: AudioBufferë¥¼ WAV Blobë¡œ ë³€í™˜
      const wavBlob = audioBufferToWav(renderedBuffer)
      
      // ì •ë¦¬
      audioContext.close().catch(() => {})
      
      console.log('âœ… ì˜¤ë””ì˜¤ ë¯¹ì‹± ì™„ë£Œ:', {
        size: wavBlob.size,
        type: wavBlob.type
      })
      
      return wavBlob
      
    } catch (error: any) {
      console.error('ì˜¤ë””ì˜¤ ë¯¹ì‹± ì˜¤ë¥˜:', error)
      
      // ì •ë¦¬ ì‘ì—…
      try {
        if (audioContext && audioContext.state !== 'closed') {
          await audioContext.close().catch(() => {})
        }
      } catch {}
      
      // ë” ìì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
      const errorMsg = error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
      let userMessage = 'ì˜¤ë””ì˜¤ ë¯¹ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\n'
      userMessage += `ì˜¤ë¥˜: ${errorMsg}\n\n`
      
      // ë¸Œë¼ìš°ì €/ëª¨ë°”ì¼ ê´€ë ¨ ì•ˆë‚´
      if (errorMsg.includes('AudioContext') || errorMsg.includes('webkitAudioContext')) {
        userMessage += 'ğŸ’¡ í•´ê²° ë°©ë²•:\n'
        userMessage += '1. ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”\n'
        userMessage += '2. ë‹¤ë¥¸ ë¸Œë¼ìš°ì €(Chrome, Safari)ì—ì„œ ì‹œë„í•´ë³´ì„¸ìš”\n'
        userMessage += '3. ëª¨ë°”ì¼ ë°ì´í„° ëŒ€ì‹  Wi-Fië¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”\n'
      } else if (errorMsg.includes('ë””ì½”ë”©') || errorMsg.includes('decode')) {
        userMessage += 'ğŸ’¡ ì˜¤ë””ì˜¤ íŒŒì¼ í˜•ì‹ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ BGM íŒŒì¼ì„ ì„ íƒí•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n'
      } else if (errorMsg.includes('BGM') || errorMsg.includes('ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')) {
        userMessage += 'ğŸ’¡ BGM íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ BGMì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n'
      } else {
        userMessage += 'ğŸ’¡ ë¸Œë¼ìš°ì €ë¥¼ ìƒˆë¡œê³ ì¹¨í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.\n'
      }
      
      throw new Error(userMessage)
    }
  }
  
  // AudioBufferë¥¼ WAV Blobë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
  const audioBufferToWav = (buffer: AudioBuffer): Blob => {
    const numChannels = buffer.numberOfChannels
    const sampleRate = buffer.sampleRate
    const length = buffer.length
    const bytesPerSample = 2
    const blockAlign = numChannels * bytesPerSample
    const byteRate = sampleRate * blockAlign
    const dataSize = length * blockAlign
    const bufferSize = 44 + dataSize
    
    const arrayBuffer = new ArrayBuffer(bufferSize)
    const view = new DataView(arrayBuffer)
    const samples: Float32Array[] = []
    
    // ì±„ë„ ë°ì´í„° ì¶”ì¶œ
    for (let channel = 0; channel < numChannels; channel++) {
      samples.push(buffer.getChannelData(channel))
    }
    
    // WAV í—¤ë” ì‘ì„±
    const writeString = (offset: number, string: string) => {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i))
      }
    }
    
    writeString(0, 'RIFF')
    view.setUint32(4, bufferSize - 8, true)
    writeString(8, 'WAVE')
    writeString(12, 'fmt ')
    view.setUint32(16, 16, true) // fmt chunk size
    view.setUint16(20, 1, true) // audio format (PCM)
    view.setUint16(22, numChannels, true)
    view.setUint32(24, sampleRate, true)
    view.setUint32(28, byteRate, true)
    view.setUint16(32, blockAlign, true)
    view.setUint16(34, 16, true) // bits per sample
    writeString(36, 'data')
    view.setUint32(40, dataSize, true)
    
    // PCM ë°ì´í„° ì‘ì„±
    let offset = 44
    for (let i = 0; i < length; i++) {
      for (let channel = 0; channel < numChannels; channel++) {
        const sample = Math.max(-1, Math.min(1, samples[channel][i]))
        view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true)
        offset += 2
      }
    }
    
    return new Blob([arrayBuffer], { type: 'audio/wav' })
  }

  /**
   * ë°©ì†¡ ìƒì„± í•¨ìˆ˜
   * 
   * [êµ¬í˜„ ëª…ì„¸ - ì œë¯¸ë‚˜ì´ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜]
   * 1. ì„œë²„ API(/api/generate-announcement)ë¥¼ í˜¸ì¶œí•´ì„œ AI ëª©ì†Œë¦¬(Voice)ë¥¼ ë°›ì•„ì˜¨ë‹¤
   * 2. ì„ íƒí•œ BGM íŒŒì¼ì„ fetchë¡œ ê°€ì ¸ì˜¨ë‹¤
   * 3. Web Audio API (AudioContext)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ì˜¤ë””ì˜¤ë¥¼ í•©ì„±í•œë‹¤
   *    - Voice ë³¼ë¥¨: 1.0 (100%)
   *    - BGM ë³¼ë¥¨: 0.2 (20% - ëª©ì†Œë¦¬ì— ë¬»íˆì§€ ì•Šê²Œ ì€ì€í•˜ê²Œ)
   *    - ê¸¸ì´ ë§ì¶¤: ëª©ì†Œë¦¬ê°€ ëë‚˜ë©´ BGMë„ í˜ì´ë“œì•„ì›ƒ(Fade out) ë˜ë©° 2ì´ˆ ë’¤ ëë‚˜ê²Œ ì²˜ë¦¬
   * 
   * ëª¨ë“  ì²˜ë¦¬ëŠ” ì‚¬ì¥ë‹˜ í°(ë¸Œë¼ìš°ì €)ì—ì„œ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œë¡œ ì¦‰ì„ ì²˜ë¦¬ë©ë‹ˆë‹¤.
   */
  const handleGenerate = async () => {
    if (!text.trim()) {
      alert('ì•ˆë‚´ ë¬¸êµ¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.')
      return
    }

    setIsGenerating(true)
    setError(null)
    setAudioUrl(null)
    setAudioBlob(null)

    try {
      // Step 1: BGM ì„ íƒ ì—¬ë¶€ í™•ì¸
      const bgmUrl = selectedBgm !== 'none' 
        ? bgmFiles.find(f => {
            if (selectedBgm.startsWith('public_')) {
              return f.type === 'public' && selectedBgm === `public_${f.name}`
            } else if (selectedBgm.startsWith('private_')) {
              return f.type === 'private' && selectedBgm === `private_${f.name}`
            }
            return false
          })?.url
        : undefined

      console.log('ë°©ì†¡ ìƒì„± ì‹œì‘:', { text: text.substring(0, 50), hasBgm: !!bgmUrl })

      // Step 2: í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ TTS ìƒì„± (Web Speech API ì‚¬ìš© - ì„œë²„ ë¶ˆí•„ìš”)
      // ë¸Œë¼ìš°ì € ë‚´ì¥ ìŒì„± í•©ì„± ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ì„œë²„ ì—†ì´ ì²˜ë¦¬
      console.log('ğŸ”„ í´ë¼ì´ì–¸íŠ¸ì—ì„œ TTS ìƒì„± ì‹œì‘ (Web Speech API)...')
      
      let voiceBlob: Blob
      try {
        voiceBlob = await generateSpeechWithWebAPI(
          text,
          voiceLang,
          voiceSpeed,
          voiceGender
        )
        console.log('âœ… Voice ìƒì„± ì™„ë£Œ (Web Speech API):', {
          size: voiceBlob.size,
          type: voiceBlob.type
        })
        
        // ìµœì¢… Blob ê²€ì¦
        if (voiceBlob.size === 0) {
          throw new Error('ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
        }
        
        // ìµœì†Œ í¬ê¸° í™•ì¸ (1KB ì´ìƒì´ì–´ì•¼ í•¨)
        if (voiceBlob.size < 1024) {
          console.warn('ìƒì„±ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤:', voiceBlob.size, 'bytes')
        }
      } catch (ttsError: any) {
        console.error('TTS ìƒì„± ì‹¤íŒ¨:', ttsError)
        const errorMessage = ttsError.message || 'ìŒì„± ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
        throw new Error(`ìŒì„± ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: ${errorMessage}\n\në¸Œë¼ìš°ì €ê°€ ìŒì„± í•©ì„±ì„ ì§€ì›í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¸Œë¼ìš°ì €(Chrome, Safari)ì—ì„œ ì‹œë„í•´ë³´ì„¸ìš”.`)
      }

      // Step 4: BGM ë¯¹ì‹± (í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ - ì‚¬ì¥ë‹˜ í°ì—ì„œ ì¦‰ì„ ì²˜ë¦¬)
      // ì‚¬ìš©ìê°€ BGMì„ ì„ íƒí–ˆìœ¼ë©´ Web Audio APIë¡œ ìŒì•…ê³¼ ëª©ì†Œë¦¬ë¥¼ í•©ì„±
      let finalBlob = voiceBlob
      
      if (bgmUrl) {
        console.log('ğŸµ BGMì´ ì„ íƒë¨, í´ë¼ì´ì–¸íŠ¸ì—ì„œ Web Audio APIë¡œ ë¯¹ì‹± ì‹œì‘...')
        
        try {
          console.log('í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ BGM ë¯¹ì‹± ì‹œì‘:', { bgmUrl })
          
          // Web Audio APIë¥¼ ì‚¬ìš©í•˜ì—¬ Voice + BGM í•©ì„±
          // Voice: 100%, BGM: 20% ë³¼ë¥¨
          // ëª©ì†Œë¦¬ ëë‚˜ë©´ BGM í˜ì´ë“œì•„ì›ƒ í›„ 2ì´ˆ ë’¤ ì¢…ë£Œ
          finalBlob = await mixAudio(voiceBlob, bgmUrl)
          
          console.log('âœ… í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ BGM ë¯¹ì‹± ì„±ê³µ:', {
            voiceSize: voiceBlob.size,
            mixedSize: finalBlob.size,
            ratio: (finalBlob.size / voiceBlob.size).toFixed(2)
          })
        } catch (mixError: any) {
          console.error('âŒ í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ BGM ë¯¹ì‹± ì‹¤íŒ¨:', mixError)
          console.warn('Voiceë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.')
          
          // ì‚¬ìš©ìì—ê²Œ BGM ë¯¹ì‹± ì‹¤íŒ¨ë¥¼ ì•Œë¦¼
          const mixErrorMessage = mixError.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'
          console.warn('BGM ë¯¹ì‹± ì‹¤íŒ¨ ìƒì„¸:', {
            error: mixErrorMessage,
            bgmUrl,
            voiceSize: voiceBlob.size
          })
          
          // í´ë¼ì´ì–¸íŠ¸ ë¯¹ì‹± ì‹¤íŒ¨ ì‹œ Voiceë§Œ ì‚¬ìš© (ì—ëŸ¬ë¥¼ throwí•˜ì§€ ì•ŠìŒ)
          // ë‹¨, ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ì„ í‘œì‹œ
          setError(`âš ï¸ BGM ë¯¹ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. Voiceë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n\nì˜¤ë¥˜: ${mixErrorMessage}\n\nVoice ì˜¤ë””ì˜¤ëŠ” ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.`)
          finalBlob = voiceBlob
        }
      }

      // 5. ê²°ê³¼ í‘œì‹œ
      const url = URL.createObjectURL(finalBlob)
      console.log('ì˜¤ë””ì˜¤ URL ìƒì„±:', {
        url,
        size: finalBlob.size,
        type: finalBlob.type
      })
      
      // ì˜¤ë””ì˜¤ ì¬ìƒ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
      const testAudio = new Audio(url)
      
      return new Promise<void>((resolve) => {
        let loaded = false
        
        testAudio.onloadeddata = () => {
          if (!loaded) {
            loaded = true
            console.log('ì˜¤ë””ì˜¤ ë¡œë“œ ì„±ê³µ:', {
              duration: testAudio.duration,
              readyState: testAudio.readyState,
              size: finalBlob.size
            })
            
            // ì˜¤ë””ì˜¤ê°€ ì‹¤ì œë¡œ ì¬ìƒ ê°€ëŠ¥í•œì§€ í™•ì¸
            if (testAudio.duration === 0 || !isFinite(testAudio.duration)) {
              console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ë¶ˆê°€ëŠ¥:', {
                duration: testAudio.duration,
                readyState: testAudio.readyState
              })
              setError('ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.')
              resolve()
              return
            }
            
            setAudioUrl(url)
            setAudioBlob(finalBlob)
            resolve()
          }
        }
        
        testAudio.onerror = (e: any) => {
          console.error('ì˜¤ë””ì˜¤ ë¡œë“œ ì‹¤íŒ¨:', {
            error: e,
            errorCode: testAudio.error?.code,
            errorMessage: testAudio.error?.message
          })
          setError('ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì¬ìƒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.')
          resolve()
        }
        
        testAudio.oncanplaythrough = () => {
          if (!loaded) {
            testAudio.onloadeddata?.(new Event('loadeddata'))
          }
        }
        
        // íƒ€ì„ì•„ì›ƒ ì„¤ì • (5ì´ˆ)
        setTimeout(() => {
          if (!loaded) {
            console.warn('ì˜¤ë””ì˜¤ ë¡œë“œ íƒ€ì„ì•„ì›ƒ, ê³„ì† ì§„í–‰')
            setAudioUrl(url)
            setAudioBlob(finalBlob)
            resolve()
          }
        }, 5000)
        
        testAudio.load()
      })

    } catch (error: any) {
      console.error('ë°©ì†¡ ìƒì„± ì‹¤íŒ¨:', error)
      const errorMessage = error.message || 'ë°©ì†¡ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
      setError(errorMessage)
      
      // ìƒì„¸í•œ ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
      let alertMessage = `ë°©ì†¡ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\n${errorMessage}`
      
      // Python/gTTS ê´€ë ¨ ì—ëŸ¬ì¸ ê²½ìš° ì¶”ê°€ ì•ˆë‚´
      if (errorMessage.includes('Python') || errorMessage.includes('gtts') || errorMessage.includes('ì„œë²„')) {
        alertMessage += '\n\nğŸ“± ëª¨ë°”ì¼ì—ì„œëŠ” ì„œë²„ì—ì„œ ì²˜ë¦¬ë˜ë¯€ë¡œ ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.\në¬¸ì œê°€ ê³„ì†ë˜ë©´ ì„œë²„ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.'
      } else if (errorMessage.includes('ë„¤íŠ¸ì›Œí¬')) {
        alertMessage += '\n\nğŸ“± ëª¨ë°”ì¼ ë°ì´í„°ë¥¼ ì‚¬ìš© ì¤‘ì´ë©´ Wi-Fië¡œ ì „í™˜í•´ë³´ì„¸ìš”.'
      }
      
      // ëª¨ë°”ì¼ì—ì„œ alert ëŒ€ì‹  ì—ëŸ¬ ìƒíƒœë§Œ í‘œì‹œ (alertëŠ” ì‚¬ìš©ì ê²½í—˜ì„ ë°©í•´í•¨)
      console.error('ë°©ì†¡ ìƒì„± ì—ëŸ¬:', errorMessage)
    } finally {
      setIsGenerating(false)
    }
  }

  // ì˜¤ë””ì˜¤ ì¬ìƒ/ì¼ì‹œì •ì§€
  const togglePlay = () => {
    if (audioRef.current) {
      if (isPlaying) {
        audioRef.current.pause()
      } else {
        audioRef.current.play()
      }
      setIsPlaying(!isPlaying)
    }
  }

  // ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
  const handleDownload = () => {
    if (!audioBlob) return

    const url = URL.createObjectURL(audioBlob)
    const a = document.createElement('a')
    a.href = url
    a.download = `ì•ˆë‚´ë°©ì†¡_${Date.now()}.mp3`
    document.body.appendChild(a)
    a.click()
    document.body.removeChild(a)
    URL.revokeObjectURL(url)
  }

  return (
    <div className="min-h-screen pb-24 bg-gray-50">
      {/* í—¤ë” */}
      <header className="bg-white border-b border-gray-200 sticky top-0 z-30 shadow-sm">
        <div className="max-w-md mx-auto px-4 py-3 flex items-center gap-3">
          <button
            onClick={() => router.back()}
            className="p-2 hover:bg-gray-100 rounded-full transition active:bg-gray-200"
            aria-label="ë’¤ë¡œê°€ê¸°"
          >
            <ArrowLeft size={20} />
          </button>
          <h1 className="text-lg sm:text-xl font-bold text-gray-900 flex items-center gap-2">
            <Mic size={20} className="sm:w-6 sm:h-6" />
            <span className="hidden sm:inline">ì•ˆë‚´ë°©ì†¡ ìƒì„±ê¸°</span>
            <span className="sm:hidden">ë°©ì†¡ ìƒì„±</span>
          </h1>
        </div>
      </header>

      {/* ë©”ì¸ ì»¨í…ì¸  */}
      <main className="max-w-md mx-auto px-4 py-4 sm:py-6">
        <div className="bg-white rounded-2xl shadow-sm p-4 sm:p-6 space-y-4 sm:space-y-6">
          {/* ì•ˆë‚´ */}
          <div className="text-center">
            <div className="text-3xl sm:text-4xl mb-2">ğŸ™ï¸</div>
            <h2 className="text-lg sm:text-xl font-bold text-gray-900 mb-1">AI ë§¤ì¥ ì•ˆë‚´ë°©ì†¡ ì œì‘ì†Œ</h2>
            <p className="text-xs sm:text-sm text-gray-600">í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ì•ˆë‚´ë°©ì†¡ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤</p>
          </div>

          {/* BGM ì„¤ì • */}
          <div>
            <label className="block text-sm font-semibold text-gray-700 mb-2">
              <Music size={16} className="inline mr-1" />
              ë°°ê²½ìŒì•… (BGM) <span className="text-xs text-gray-500 font-normal">(ì„ íƒì‚¬í•­)</span>
            </label>
            <p className="text-xs text-gray-500 mb-2">
              âœ… ëª¨ë°”ì¼ì—ì„œë„ BGM ë¯¹ì‹±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤ (ì„œë²„ì—ì„œ ì²˜ë¦¬)
            </p>
            
            <div className="space-y-3">
              <select
                value={selectedBgm}
                onChange={(e) => setSelectedBgm(e.target.value)}
                className="w-full px-4 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E]"
                disabled={loadingBgm || uploadingBgm}
              >
                <option value="none">ë°°ê²½ìŒì•… ì—†ìŒ</option>
                {/* ê³µìš© BGM */}
                {bgmFiles.filter(f => f.type === 'public').length > 0 && (
                  <optgroup label="ğŸ”Š ê³µìš© BGM">
                    {bgmFiles
                      .filter(f => f.type === 'public')
                      .map((file) => (
                        <option key={`public_${file.name}`} value={`public_${file.name}`}>
                          {file.name.replace(/^\d+_/, '')}
                        </option>
                      ))}
                  </optgroup>
                )}
                {/* ê°œì¸ BGM */}
                {bgmFiles.filter(f => f.type === 'private').length > 0 && (
                  <optgroup label="ğŸµ ë‚´ BGM">
                    {bgmFiles
                      .filter(f => f.type === 'private')
                      .map((file) => (
                        <option key={`private_${file.name}`} value={`private_${file.name}`}>
                          {file.name.replace(/^\d+_/, '')}
                        </option>
                      ))}
                  </optgroup>
                )}
              </select>

              {loadingBgm && (
                <p className="text-xs text-gray-500 text-center">BGM ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...</p>
              )}

              {/* BGM ì—…ë¡œë“œ */}
              {user && (
                <>
                  <label className="block">
                    <input
                      type="file"
                      accept="audio/*"
                      className="hidden"
                      onChange={(e) => {
                        const file = e.target.files?.[0]
                        if (file) handleBgmUpload(file)
                      }}
                      disabled={uploadingBgm}
                    />
                    <div className="flex items-center justify-center gap-2 px-4 py-2 border-2 border-dashed border-gray-300 rounded-lg cursor-pointer hover:border-[#1A2B4E] transition">
                      {uploadingBgm ? (
                        <>
                          <Loader2 size={16} className="animate-spin text-gray-400" />
                          <span className="text-sm text-gray-500">ì—…ë¡œë“œ ì¤‘...</span>
                        </>
                      ) : (
                        <>
                          <Upload size={16} className="text-gray-400" />
                          <span className="text-sm text-gray-600">ê°œì¸ BGM ì—…ë¡œë“œ</span>
                        </>
                      )}
                    </div>
                  </label>
                </>
              )}

              {!user && (
                <p className="text-xs text-gray-500 text-center">ë¡œê·¸ì¸í•˜ë©´ BGMì„ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>
              )}
            </div>
          </div>

          {/* ìŒì„± ì„¤ì • */}
          <div>
            <label className="block text-sm font-semibold text-gray-700 mb-2">
              ğŸ¤ ìŒì„± ì„¤ì •
            </label>
            <div className="space-y-3">
              {/* ì–¸ì–´ ì„ íƒ */}
              <div>
                <label className="block text-xs text-gray-600 mb-1">ì–¸ì–´</label>
                <select
                  value={voiceLang}
                  onChange={(e) => setVoiceLang(e.target.value)}
                  className="w-full px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E] text-sm"
                  disabled={isGenerating}
                >
                  <option value="ko">í•œêµ­ì–´</option>
                  <option value="en">ì˜ì–´</option>
                  <option value="ja">ì¼ë³¸ì–´</option>
                  <option value="zh">ì¤‘êµ­ì–´</option>
                  <option value="es">ìŠ¤í˜ì¸ì–´</option>
                  <option value="fr">í”„ë‘ìŠ¤ì–´</option>
                  <option value="de">ë…ì¼ì–´</option>
                </select>
              </div>

              {/* ì†ë„ ì„ íƒ */}
              <div>
                <label className="block text-xs text-gray-600 mb-1">ì†ë„</label>
                <select
                  value={voiceSpeed}
                  onChange={(e) => setVoiceSpeed(e.target.value as 'normal' | 'slow')}
                  className="w-full px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E] text-sm"
                  disabled={isGenerating}
                >
                  <option value="normal">ì¼ë°˜ ì†ë„</option>
                  <option value="slow">ëŠë¦° ì†ë„</option>
                </select>
              </div>

              {/* ìŒì„± ì„±ë³„/ìŠ¤íƒ€ì¼ ì„ íƒ */}
              <div>
                <label className="block text-xs text-gray-600 mb-1">ìŒì„± ìŠ¤íƒ€ì¼</label>
                <select
                  value={voiceGender}
                  onChange={(e) => {
                    const gender = e.target.value as 'male' | 'female' | 'neutral'
                    setVoiceGender(gender)
                    // ì–¸ì–´ë³„ ê¸°ë³¸ TLD ì„¤ì •
                    if (voiceLang === 'ko') {
                      if (gender === 'male') {
                        setVoiceTld('com')
                      } else if (gender === 'female') {
                        setVoiceTld('co.kr')
                      } else {
                        setVoiceTld('com')
                      }
                    } else if (voiceLang === 'en') {
                      if (gender === 'male') {
                        setVoiceTld('com')
                      } else if (gender === 'female') {
                        setVoiceTld('co.uk')
                      } else {
                        setVoiceTld('com')
                      }
                    }
                  }}
                  className="w-full px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E] text-sm"
                  disabled={isGenerating}
                >
                  <option value="neutral">ê¸°ë³¸ ìŒìƒ‰</option>
                  <option value="male">ë‚¨ì„± ìŒìƒ‰</option>
                  <option value="female">ì—¬ì„± ìŒìƒ‰</option>
                </select>
                <p className="text-xs text-gray-500 mt-1">ì–¸ì–´ë³„ë¡œ ìŒìƒ‰ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤</p>
              </div>

              {/* ê³ ê¸‰ ì˜µì…˜ (TLD ì§ì ‘ ì„ íƒ) */}
              {voiceLang === 'ko' && (
                <details className="text-xs">
                  <summary className="text-gray-600 cursor-pointer hover:text-gray-800">
                    ê³ ê¸‰ ì˜µì…˜ (TLD) - ìŒìƒ‰ ë¯¸ì„¸ ì¡°ì •
                  </summary>
                  <div className="mt-2 space-y-2">
                    <select
                      value={voiceTld}
                      onChange={(e) => setVoiceTld(e.target.value)}
                      className="w-full px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E] text-sm"
                      disabled={isGenerating}
                    >
                      <option value="com">ê¸°ë³¸ (com) - í‘œì¤€ ìŒìƒ‰</option>
                      <option value="co.kr">í•œêµ­ (co.kr) - ë¶€ë“œëŸ¬ìš´ ìŒìƒ‰</option>
                    </select>
                    <p className="text-xs text-gray-500 px-1">
                      ğŸ’¡ ì°¸ê³ : gTTSëŠ” TLDë§Œìœ¼ë¡œëŠ” ëª…í™•í•œ ì„±ë³„ êµ¬ë¶„ì´ ì–´ë µìŠµë‹ˆë‹¤. 
                      í•œêµ­ì–´ ê¸°ë³¸ ìŒì„±ì€ ì´ë¯¸ ì—¬ì„± í†¤ì…ë‹ˆë‹¤. TLDëŠ” ë¯¸ì„¸í•œ ìŒìƒ‰ ì°¨ì´ë§Œ ì œê³µí•©ë‹ˆë‹¤.
                    </p>
                  </div>
                </details>
              )}
            </div>
          </div>

          {/* ì•ˆë‚´ ë¬¸êµ¬ */}
          <div>
            <label className="block text-sm font-semibold text-gray-700 mb-2">
              ì•ˆë‚´ ë¬¸êµ¬
            </label>
            <textarea
              value={text}
              onChange={(e) => setText(e.target.value)}
              placeholder="ì ì‹œ í›„ ì˜ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì°¾ì•„ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
              className="w-full h-32 px-4 py-3 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-[#1A2B4E] resize-none"
              disabled={isGenerating}
            />
            <p className="text-xs text-gray-500 mt-1 text-right">{text.length}ì</p>
          </div>

          {/* ìƒì„± ë²„íŠ¼ */}
          <button
            onClick={handleGenerate}
            disabled={isGenerating || !text.trim()}
            className="w-full bg-[#1A2B4E] text-white py-3 sm:py-4 rounded-xl font-bold hover:bg-[#1A2B4E]/90 active:bg-[#1A2B4E]/80 transition shadow-lg disabled:opacity-50 disabled:cursor-not-allowed flex items-center justify-center gap-2 text-sm sm:text-base"
            style={{ touchAction: 'manipulation' }}
          >
            {isGenerating ? (
              <>
                <Loader2 size={18} className="animate-spin sm:w-5 sm:h-5" />
                <span>ìƒì„± ì¤‘...</span>
              </>
            ) : (
              <>
                <Mic size={18} className="sm:w-5 sm:h-5" />
                <span>ë°©ì†¡ ë§Œë“¤ê¸°</span>
              </>
            )}
          </button>

          {/* ì˜¤ë¥˜ ë©”ì‹œì§€ */}
          {error && (
            <div className="bg-red-50 border border-red-200 rounded-lg p-3 sm:p-4">
              <p className="text-xs sm:text-sm text-red-700 whitespace-pre-wrap break-words">
                âš ï¸ {error}
              </p>
              {(error.includes('Python') || error.includes('ì„œë²„') || error.includes('gtts') || error.includes('FFmpeg')) && (
                <div className="mt-2 p-2 bg-white rounded border border-red-200">
                  <p className="text-xs text-red-600 font-semibold mb-1">ğŸ“ í•´ê²° ë°©ë²•:</p>
                  <p className="text-xs text-red-600 mb-2">
                    ì´ ë„êµ¬ëŠ” ì„œë²„ì—ì„œ ì²˜ë¦¬ë©ë‹ˆë‹¤. ëª¨ë°”ì¼ì—ì„œëŠ” ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.
                  </p>
                  <p className="text-xs text-red-600">
                    ë¬¸ì œê°€ ê³„ì†ë˜ë©´ ì„œë²„ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ê±°ë‚˜ ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.
                  </p>
                </div>
              )}
              {(error.includes('ë„¤íŠ¸ì›Œí¬') || error.includes('ì‹œê°„ì´ ì´ˆê³¼')) && (
                <div className="mt-2 p-2 bg-white rounded border border-red-200">
                  <p className="text-xs text-red-600 font-semibold mb-1">ğŸ“ í•´ê²° ë°©ë²•:</p>
                  <ul className="text-xs text-red-600 space-y-1 list-disc ml-4">
                    <li>ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”</li>
                    <li>Wi-Fië¥¼ ì‚¬ìš© ì¤‘ì´ë©´ ë°ì´í„°ë¡œ ì „í™˜í•´ë³´ì„¸ìš” (ë˜ëŠ” ê·¸ ë°˜ëŒ€)</li>
                    <li>ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”</li>
                  </ul>
                </div>
              )}
            </div>
          )}

          {/* ê²°ê³¼ */}
          {audioUrl && audioBlob && (
            <div className="border-t border-gray-200 pt-6 space-y-4">
              <h3 className="font-bold text-gray-900">ìƒì„±ëœ ë°©ì†¡</h3>
              
              {/* ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ */}
              <div className="bg-gray-50 rounded-lg p-4 space-y-4">
                <audio
                  ref={audioRef}
                  src={audioUrl}
                  onPlay={() => setIsPlaying(true)}
                  onPause={() => setIsPlaying(false)}
                  onEnded={() => setIsPlaying(false)}
                  onTimeUpdate={() => {
                    // ì§„í–‰ë°” ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ê°•ì œ ë¦¬ë Œë”ë§
                    if (audioRef.current) {
                      setVolume(audioRef.current.volume)
                    }
                  }}
                  className="w-full"
                  controls
                />
                
                <div className="flex items-center justify-center gap-3">
                  <button
                    onClick={togglePlay}
                    className="w-12 h-12 bg-[#1A2B4E] text-white rounded-full flex items-center justify-center hover:bg-[#1A2B4E]/90 transition"
                  >
                    {isPlaying ? <Pause size={20} /> : <Play size={20} />}
                  </button>
                  
                  <button
                    onClick={handleDownload}
                    className="px-4 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600 transition flex items-center gap-2"
                  >
                    <Download size={16} />
                    <span className="text-sm font-medium">ë‹¤ìš´ë¡œë“œ</span>
                  </button>
                </div>
              </div>
            </div>
          )}

          {/* ì•ˆë‚´ ë©”ì‹œì§€ */}
          {!isGenerating && !audioUrl && (
            <div className="bg-blue-50 border border-blue-200 rounded-lg p-3 sm:p-4">
              <p className="text-xs sm:text-sm text-blue-800 mb-2 font-semibold">
                ğŸ’¡ ì‚¬ìš© ë°©ë²•:
              </p>
              <ul className="text-xs text-blue-700 space-y-1 ml-4 list-disc">
                <li>ì•ˆë‚´ ë¬¸êµ¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”</li>
                <li>BGMì„ ì„ íƒí•˜ê±°ë‚˜ ì—…ë¡œë“œí•˜ì„¸ìš” (ì„ íƒì‚¬í•­)</li>
                <li>"ë°©ì†¡ ë§Œë“¤ê¸°" ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”</li>
              </ul>
              <p className="text-xs text-blue-600 mt-3">
                âœ… ëª¨ë°”ì¼ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤ (ì„œë²„ + í´ë¼ì´ì–¸íŠ¸ ì²˜ë¦¬)
              </p>
              <p className="text-xs text-blue-600 mt-1">
                ğŸ“± ëª¨ë°”ì¼ì—ì„œë„ BGM ë¯¹ì‹±ì´ ìë™ìœ¼ë¡œ ì§€ì›ë©ë‹ˆë‹¤
              </p>
            </div>
          )}
        </div>
      </main>

      <BottomNav />
    </div>
  )
}

